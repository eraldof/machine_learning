control = grid_ctrl
)
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "everything"
)
treinamento = wf %>%
workflow_map(
fn = "tune_grid",
resamples = vfold,
grid = data.frame(grid_knn, grid_svm, grid_svm),
control = grid_control
)
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = data.frame(grid_knn, grid_svm, grid_svm),
control = grid_control
)
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = 5,
control = grid_control,
metrics = metrica
)
autoplot(treinamento)
bind_cols(grid_knn, grid_elastic, grid_svm)
gridr <- bind_cols(grid_knn, grid_elastic, grid_svm)
gridr
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = gridr,
control = grid_control,
metrics = metrica
)
gridr <- bind_cols(grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L),
grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L),
grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_elastic"), size = 50L)
)
rm(list = ls())
setwd("C:/Users/erald/Desktop/Faculdade/Aprendizagem de Maquina/machine_learning")
data <- read.csv("energy_efficiency_data.csv")
set.seed(0)
id <- sample(1:nrow(data), 0.1 * nrow(data))
feature <- sample(1:ncol(data), 2)
data[id,feature[1]] <- NA
id <- sample(1:nrow(data), 0.1 * nrow(data))
data[id, feature[2]] <- NA
rm(id)
rm(feature)
set.seed(0)
splitted <- initial_split(data, prop = 0.8, strata = "Cooling_Load")
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = Cooling_Load~. , data) %>%
step_impute_knn(all_predictors(), impute_with = c("Relative_Compactness", "Surface_Area", "Wall_Area", "Roof_Area", "Overall_Height"), neighbors = 10) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
step_corr(all_predictors())
elastic <-
linear_reg(penalty = tune(), mixture = tune()) |>
set_mode("regression") |>
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune(),
dist_power = tune(),
weight_func = "gaussian"
) |>
set_mode("regression") |>
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) |>
set_mode("regression") |>
set_engine("kernlab")
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "everything"
)
vfold <-
treinamento |>
vfold_cv(v = 10, strata = Cooling_Load)
metrica <- metric_set(rmse)
wf <- workflow_set(
preproc = list(receita),
models = list(modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic)
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
wf
set.seed(0)
gridr <- bind_cols(grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L),
grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L),
grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_elastic"), size = 50L)
)
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = gridr,
control = grid_control,
metrics = metrica
)
autoplot(treinamento)
rm(list = ls())
setwd("C:/Users/erald/Desktop/Faculdade/Aprendizagem de Maquina/machine_learning")
data <- read.csv("energy_efficiency_data.csv")
set.seed(0)
id <- sample(1:nrow(data), 0.1 * nrow(data))
feature <- sample(1:ncol(data), 2)
data[id,feature[1]] <- NA
id <- sample(1:nrow(data), 0.1 * nrow(data))
data[id, feature[2]] <- NA
rm(id)
rm(feature)
set.seed(0)
splitted <- initial_split(data, prop = 0.8, strata = "Cooling_Load")
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = Cooling_Load~. , data) %>%
step_impute_knn(all_predictors(), impute_with = c("Relative_Compactness", "Surface_Area", "Wall_Area", "Roof_Area", "Overall_Height"), neighbors = 10) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
step_corr(all_predictors())
elastic <-
linear_reg(penalty = tune(), mixture = tune()) |>
set_mode("regression") |>
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune(),
dist_power = tune(),
weight_func = "gaussian"
) |>
set_mode("regression") |>
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) |>
set_mode("regression") |>
set_engine("kernlab")
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "everything"
)
vfold <-
treinamento |>
vfold_cv(v = 10, strata = Cooling_Load)
metrica <- metric_set(rmse)
wf <- workflow_set(
preproc = list(receita),
models = list(modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic)
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
wf
set.seed(0)
gridr <- bind_cols(grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L),
grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L),
grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_elastic"), size = 50L)
)
gridr
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = gridr,
control = grid_control,
metrics = metrica
)
rm(list = ls())
setwd("C:/Users/erald/Desktop/Faculdade/Aprendizagem de Maquina/machine_learning")
data <- read.csv("energy_efficiency_data.csv")
set.seed(0)
id <- sample(1:nrow(data), 0.1 * nrow(data))
feature <- sample(1:ncol(data), 2)
data[id,feature[1]] <- NA
id <- sample(1:nrow(data), 0.1 * nrow(data))
data[id, feature[2]] <- NA
rm(id)
rm(feature)
set.seed(0)
splitted <- initial_split(data, prop = 0.8, strata = "Cooling_Load")
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = Cooling_Load~. , data) %>%
step_impute_knn(all_predictors(), impute_with = c("Relative_Compactness", "Surface_Area", "Wall_Area", "Roof_Area", "Overall_Height"), neighbors = 10) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
step_corr(all_predictors())
elastic <-
linear_reg(penalty = tune(), mixture = tune()) |>
set_mode("regression") |>
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune(),
dist_power = tune(),
weight_func = "gaussian"
) |>
set_mode("regression") |>
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) |>
set_mode("regression") |>
set_engine("kernlab")
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "everything"
)
vfold <-
treinamento |>
vfold_cv(v = 10, strata = Cooling_Load)
metrica <- metric_set(rmse)
wf <- workflow_set(
preproc = list(receita),
models = list(modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic)
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
wf
set.seed(0)
gridr <- bind_cols(grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L),
grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L),
grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_elastic"), size = 50L)
)
gridr
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = gridr,
control = grid_control,
metrics = metrica
)
gridr[,c(1,2)]
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = list(modelo_knn = gridr[,c(1,2)],
modelo_svm = gridr[,c(3,5)],
modelo_elastic = gridr[,c(6,7)]),
control = grid_control,
metrics = metrica
)
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = list(modelo_knn = as.data.frame(gridr[,c(1,2)]),
modelo_svm = as.data.frame(gridr[,c(3,5)]),
modelo_elastic = as.data.frame(gridr[,c(6,7)])),
control = grid_control,
metrics = metrica
)
grid_svm <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L) %>%
as.data.frame() %>%
mutate(cost = tune(), rbf_sigma = tune(), margin = tune())
grid_svm <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L) %>%
as.data.frame()
grid_svm
wf
grid_svm <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L) %>%
as.data.frame()
grid_knn <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L) %>%
as.data.frame()
grid_elastic <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_elastic"), size = 50L) %>%
as.data.frame()
treinamento = wf %>%
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = list(modelo_knn = grid_knn,
modelo_svm = grid_svm,
modelo_elastic = grid_elastic
),
control = grid_control,
metrics = metrica
)
rm(list = ls())
setwd("C:/Users/erald/Desktop/Faculdade/Aprendizagem de Maquina/machine_learning")
data <- read.csv("energy_efficiency_data.csv")
set.seed(0)
id <- sample(1:nrow(data), 0.1 * nrow(data))
feature <- sample(1:ncol(data), 2)
data[id,feature[1]] <- NA
id <- sample(1:nrow(data), 0.1 * nrow(data))
data[id, feature[2]] <- NA
rm(id)
rm(feature)
set.seed(0)
splitted <- initial_split(data, prop = 0.8, strata = "Cooling_Load")
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = Cooling_Load~. , data) %>%
step_impute_knn(all_predictors(), impute_with = c("Relative_Compactness", "Surface_Area", "Wall_Area", "Roof_Area", "Overall_Height"), neighbors = 10) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
step_corr(all_predictors())
elastic <-
linear_reg(penalty = tune(), mixture = tune()) |>
set_mode("regression") |>
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune(),
dist_power = tune(),
weight_func = "gaussian"
) |>
set_mode("regression") |>
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) |>
set_mode("regression") |>
set_engine("kernlab")
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "everything"
)
vfold <-
treinamento |>
vfold_cv(v = 10, strata = Cooling_Load)
metrica <- metric_set(rmse)
wf <- workflow_set(
preproc = list(receita),
models = list(modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic)
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
wf
set.seed(0)
grid_svm <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L) %>%
as.data.frame()
grid_knn <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L) %>%
as.data.frame()
grid_elastic <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_elastic"), size = 50L) %>%
as.data.frame()
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = list(modelo_knn = grid_knn,
modelo_svm = grid_svm,
modelo_elastic = grid_elastic
),
control = grid_control,
metrics = metrica
)
rm(list = ls())
setwd("C:/Users/erald/Desktop/Faculdade/Aprendizagem de Maquina/machine_learning")
data <- read.csv("energy_efficiency_data.csv")
set.seed(0)
id <- sample(1:nrow(data), 0.1 * nrow(data))
feature <- sample(1:ncol(data), 2)
data[id,feature[1]] <- NA
id <- sample(1:nrow(data), 0.1 * nrow(data))
data[id, feature[2]] <- NA
rm(id)
rm(feature)
set.seed(0)
splitted <- initial_split(data, prop = 0.8, strata = "Cooling_Load")
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = Cooling_Load~. , data) %>%
step_impute_knn(all_predictors(), impute_with = c("Relative_Compactness", "Surface_Area", "Wall_Area", "Roof_Area", "Overall_Height"), neighbors = 10) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
step_corr(all_predictors())
elastic <-
linear_reg(penalty = tune(), mixture = tune()) |>
set_mode("regression") |>
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune(),
dist_power = tune(),
weight_func = "gaussian"
) |>
set_mode("regression") |>
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) |>
set_mode("regression") |>
set_engine("kernlab")
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "everything"
)
vfold <-
treinamento |>
vfold_cv(v = 10, strata = Cooling_Load)
metrica <- metric_set(rmse)
wf <- workflow_set(
preproc = list(receita),
models = list(modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic)
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
wf
set.seed(0)
grid_svm <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L) %>%
as.data.frame()
grid_knn <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L) %>%
as.data.frame()
grid_elastic <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_elastic"), size = 50L) %>%
as.data.frame()
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = list(modelo_knn = grid_knn,
modelo_svm = grid_svm,
modelo_elastic = grid_elastic
),
control = grid_control,
metrics = metrica
)
combined_grid <- bind_rows(
modelo_knn = grid_knn,
modelo_svm = grid_svm,
modelo_elastic = grid_elastic
)
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = combined_grid,
control = grid_control,
metrics = metrica
)
grid_svm <- grid_max_entropy(wf %>% extract_parameter_set_dials("modelo_svm"), size = 50L) %>%
as.data.frame() %>% mutate(cost = tune(), rbf_sigma = tune(), margin = tune())
combined_grid <- bind_rows(
modelo_knn = grid_knn,
modelo_svm = grid_svm,
modelo_elastic = grid_elastic
)
combined_grid
wf
wf %>% extract_workflow()
wf %>% extract_workflow("modelo_knn")
treinamento = wf %>%
workflow_map(
verbose = TRUE,
seed = 0,
fn = "tune_grid",
resamples = vfold,
grid = combined_grid,
control = grid_control,
metrics = metrica
)
