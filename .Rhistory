workflow_set(
preproc = list(receita),
models = list(
modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic
),
cross = TRUE
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "resamples"
)
vfold <-
treinamento %>%
vfold_cv(v = 15, strata = charges)
metrica <- metric_set(rmse)
set.seed(2023)
grid_knn <- grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L)
grid_elastic <- grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_elastic"), size = 100L)
grid_svm <-  grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_svm"), size = 30L)
all_wf <-
all_wf %>%
option_add(grid = grid_knn, id = 'modelo_knn') %>%
option_add(grid = grid_elastic, id = 'modelo_elastic') %>%
option_add(grid = grid_svm, id = 'modelo_svm')
tunagem <-
all_wf %>%
workflow_map(
verbose = TRUE,
seed = 2023,
resamples = vfold,
control = grid_control,
metrics = metrica
)
autoplot(
tunagem,
rank_metric = "rmse",
metric = "rmse",
select_best = TRUE
) +
labs(title = "Melhor resultado dos modelos")+ ylab("rmse")+ xlab("Ranking")
best = tunagem %>%
extract_workflow_set_result("modelo_svm") %>%
select_best(metric = "rmse")
best %>%
knitr::kable(caption = "Hiperparametros")
wf_final <-
tunagem %>% extract_workflow("modelo_svm") %>%
finalize_workflow(best)
teste <-
wf_final %>%
last_fit(split = splitted)
knitr::kable(teste$.metrics, caption = "Resultados")
modelo_final <-
wf_final |>
fit(data2)
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
head(data2)
predict(modelo_final, data2)
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
yhat <- predict(modelo_final, data2)
g1 <- ggplot(data.frame(y = data2$charges, yhat = predict(modelo_final, data2)),
aes(x = yhat, y = y)) +
geom_point() + geom_line(aes(y = ychapeu_mmo), colour = "red", size = 1) +
labs(title = "Modelo SVM", subtitle = "y_ajustado vs y_real")
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
yhat <- predict(modelo_final, data2)
g1 <- ggplot(data.frame(y = data2$charges, yhat = predict(modelo_final, data2)),
aes(x = yhat, y = y)) +
geom_point() + geom_line(aes(y = ychapeu_mmo), colour = "red", linewidth = 1) +
labs(title = "Modelo SVM", subtitle = "y_ajustado vs y_real")
g1
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
yhat <- predict(modelo_final, data2)
g1 <- ggplot(data.frame(y = data2$charges, yhat = predict(modelo_final, data2)),
aes(x = yhat, y = y)) +
geom_point() + geom_line(aes(y = ychapeu_mmo), colour = "red", size = 1) +
labs(title = "Modelo SVM", subtitle = "y_ajustado vs y_real")
g1
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
yhat <- predict(modelo_final, data2)
g1 <- ggplot(data.frame(y = data2$charges, yhat = predict(modelo_final, data2)),
aes(x = yhat, y = y)) +
geom_point() + geom_line(aes(y = yhat), colour = "red", size = 1) +
labs(title = "Modelo SVM", subtitle = "y_ajustado vs y_real")
g1
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
yhat <- predict(modelo_final, data2)
g1 <- ggplot(data.frame(y = data2$charges, yhat = predict(modelo_final, data2)),
aes(x = yhat, y = y)) +
geom_point() + geom_line(aes(y = y), colour = "red", size = 1) +
labs(title = "Modelo SVM", subtitle = "y_ajustado vs y_real")
g1
dt <- data.frame(y = data2$charges, yhat = predict(modelo_final, data2))
View(dt)
# Fazendo novas previsões
dt <- data.frame("y" = data2$charges, "yhat" = predict(modelo_final, data2))
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
dt <- data.frame("y" = data2$charges, "yhat" = predict(modelo_final, data2))
g1 <- ggplot(dt,
aes(x = y, y = .pred)) +
geom_point() + geom_line(aes(y = .pred), colour = "red", size = 1) +
labs(title = "Modelo SVM", subtitle = "y_ajustado vs y_real")
g1
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
dt <- data.frame("y" = data2$charges, "yhat" = predict(modelo_final, data2))
g1 <- ggplot(dt,
aes(x = y, y = .pred)) +
geom_point() + geom_line(aes(y = y), colour = "red", size = 1) +
labs(title = "Modelo SVM", subtitle = "y_ajustado vs y_real")
g1
url = "https://raw.githubusercontent.com/eraldof/machine_learning/main/winequality-red.csv"
data3 <- read.csv(url)
skimr::skim(data3)
visdat::vis_dat(data3)
visdat::vis_cor(data3[,-3])
set.seed(2023)
splitted <- initial_split(data3, prop = 0.9, strata = quality)
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = `quality` ~ . , data3) %>%
step_YeoJohnson(all_numeric_predictors()) %>%
step_normalize(all_numeric_predictors())
elastic <-
linear_reg(penalty = tune(),
mixture = tune()
) %>%
set_mode("regression") %>%
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune()
) %>%
set_mode("regression") %>%
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) %>%
set_mode("regression") %>%
set_engine("kernlab")
all_wf <-
workflow_set(
preproc = list(receita),
models = list(
modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic
),
cross = TRUE
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "resamples"
)
vfold <-
treinamento %>%
vfold_cv(v = 15, strata = resultado_final)
elastic <-
linear_reg(penalty = tune(),
mixture = tune()
) %>%
set_mode("regression") %>%
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune()
) %>%
set_mode("regression") %>%
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) %>%
set_mode("regression") %>%
set_engine("kernlab")
all_wf <-
workflow_set(
preproc = list(receita),
models = list(
modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic
),
cross = TRUE
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "resamples"
)
vfold <-
treinamento %>%
vfold_cv(v = 15, strata = quality)
metrica <- metric_set(rmse)
set.seed(2023)
grid_knn <- grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L)
grid_elastic <- grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_elastic"), size = 100L)
grid_svm <-  grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_svm"), size = 30L)
all_wf <-
all_wf %>%
option_add(grid = grid_knn, id = 'modelo_knn') %>%
option_add(grid = grid_elastic, id = 'modelo_elastic') %>%
option_add(grid = grid_svm, id = 'modelo_svm')
tunagem <-
all_wf %>%
workflow_map(
verbose = TRUE,
seed = 2023,
resamples = vfold,
control = grid_control,
metrics = metrica
)
autoplot(
tunagem,
rank_metric = "rmse",
metric = "rmse",
select_best = TRUE
) +
labs(title = "Melhor resultado dos modelos")+ ylab("rmse")+ xlab("Ranking")
autoplot(
tunagem,
rank_metric = "rmse",
metric = "rmse",
select_best = TRUE
) +
labs(title = "Melhor resultado dos modelos")+ ylab("rmse")+ xlab("Ranking")
best = tunagem %>%
extract_workflow_set_result("modelo_knn") %>%
select_best(metric = "rmse")
best %>%
knitr::kable(caption = "Hiperparametros")
wf_final <-
tunagem %>% extract_workflow("modelo_knn") %>%
finalize_workflow(best)
teste <-
wf_final %>%
last_fit(split = splitted)
knitr::kable(teste$.metrics, caption = "Resultados")
modelo_final <-
wf_final |>
fit(data3)
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
predict(modelo_final, new_data = data3)
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
dt <- data.frame("y" = data2$charges, "yhat" = predict(modelo_final, data3))
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
dt <- data.frame("y" = data3$quality, "yhat" = predict(modelo_final, data3))
g1 <- ggplot(dt,
aes(x = y, y = .pred)) +
geom_point() + geom_line(aes(y = y), colour = "red", size = 1) +
labs(title = "Modelo KNN", subtitle = "y_ajustado vs y_real")
g1
# Fazendo novas previsões
predict(modelo_final, data3))
# Fazendo novas previsões
predict(modelo_final, data3)
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
#predict(modelo_final, data3)
url = "https://raw.githubusercontent.com/eraldof/machine_learning/main/winequality-red.csv"
data4 <- read.csv(url)
skimr::skim(data4)
visdat::vis_dat(data4)
visdat::vis_cor(data4[,])
skimr::skim(data3)
visdat::vis_dat(data3)
visdat::vis_cor(data3)
url = "https://raw.githubusercontent.com/eraldof/machine_learning/main/energy_efficiency_data.csv"
data4 <- read.csv(url)
url = "https://raw.githubusercontent.com/eraldof/machine_learning/main/energy_efficiency_data.csv"
data4 <- read.csv(url)
skimr::skim(data4)
visdat::vis_dat(data4)
visdat::vis_cor(data4)
set.seed(2023)
splitted <- initial_split(data4, prop = 0.9, strata = Cooling_Load)
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = `Cooling_load` ~ . , data4) %>%
step_corr(all_predictors())
colnames(data4)
set.seed(2023)
splitted <- initial_split(data4, prop = 0.9, strata = Cooling_Load)
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = `Cooling_Load` ~ . , data4) %>%
step_corr(all_predictors())
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
receita <- recipe(formula = `Cooling_Load` ~ . , data4) %>%
step_corr(all_predictors()) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
set.seed(2023)
splitted <- initial_split(data4, prop = 0.9, strata = Cooling_Load)
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = `Cooling_Load` ~ . , data4) %>%
step_corr(all_predictors()) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
url = "https://raw.githubusercontent.com/eraldof/machine_learning/main/energy_efficiency_data.csv"
data4 <- read.csv(url)
skimr::skim(data4)
visdat::vis_dat(data4)
visdat::vis_cor(data4)
set.seed(2023)
splitted <- initial_split(data4, prop = 0.9, strata = Cooling_Load)
treinamento <- training(splitted)
teste <- testing(splitted)
receita <- recipe(formula = `Cooling_Load` ~ . , data4) %>%
step_corr(all_predictors()) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors()) %>%
receita <- recipe(formula = `Cooling_Load` ~ . , data4) %>%
step_corr(all_predictors()) %>%
step_YeoJohnson(all_predictors()) %>%
step_normalize(all_predictors())
elastic <-
linear_reg(penalty = tune(),
mixture = tune()
) %>%
set_mode("regression") %>%
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune()
) %>%
set_mode("regression") %>%
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) %>%
set_mode("regression") %>%
set_engine("kernlab")
all_wf <-
workflow_set(
preproc = list(receita),
models = list(
modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic
),
cross = TRUE
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "resamples"
)
vfold <-
treinamento %>%
vfold_cv(v = 15L, strata = resultado_final)
elastic <-
linear_reg(penalty = tune(),
mixture = tune()
) %>%
set_mode("regression") %>%
set_engine("glmnet")
knn <-
nearest_neighbor(
neighbors = tune()
) %>%
set_mode("regression") %>%
set_engine("kknn")
svm <-
svm_rbf(
cost = tune(),
rbf_sigma = tune(),
margin = tune()
) %>%
set_mode("regression") %>%
set_engine("kernlab")
all_wf <-
workflow_set(
preproc = list(receita),
models = list(
modelo_knn = knn,
modelo_svm = svm,
modelo_elastic = elastic
),
cross = TRUE
) %>%
mutate(wflow_id = gsub("(recipe_)", "", wflow_id))
grid_control <- control_grid(
save_pred = TRUE,
save_workflow = TRUE,
parallel_over = "resamples"
)
vfold <-
treinamento %>%
vfold_cv(v = 15L, strata = Cooling_Load)
metrica <- metric_set(rmse)
set.seed(2023)
grid_knn <- grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_knn"), size = 50L)
grid_elastic <- grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_elastic"), size = 100L)
grid_svm <-  grid_max_entropy(all_wf %>% extract_parameter_set_dials("modelo_svm"), size = 30L)
all_wf <-
all_wf %>%
option_add(grid = grid_knn, id = 'modelo_knn') %>%
option_add(grid = grid_elastic, id = 'modelo_elastic') %>%
option_add(grid = grid_svm, id = 'modelo_svm')
tunagem <-
all_wf %>%
workflow_map(
verbose = TRUE,
seed = 2023,
resamples = vfold,
control = grid_control,
metrics = metrica
)
autoplot(
tunagem,
rank_metric = "rmse",
metric = "rmse",
select_best = TRUE
) +
labs(title = "Melhor resultado dos modelos")+ ylab("rmse")+ xlab("Ranking")
best = tunagem %>%
extract_workflow_set_result("modelo_svm") %>%
select_best(metric = "rmse")
best %>%
knitr::kable(caption = "Hiperparametros")
wf_final <-
tunagem %>% extract_workflow("modelo_elastic") %>%
finalize_workflow(best)
teste <-
wf_final %>%
last_fit(split = splitted)
wf_final <-
tunagem %>% extract_workflow("modelo_svm") %>%
finalize_workflow(best)
teste <-
wf_final %>%
last_fit(split = splitted)
knitr::kable(teste$.metrics, caption = "Resultados")
modelo_final <-
wf_final |>
fit(data4)
# Salvando o modelo em um arquivo serializado
#saveRDS(modelo_final, file = "modelo_final.rds")
# Lendo o arquivo serializado com o modelo final
#load(file = "modelo_final.rds")
# Fazendo novas previsões
dt <- data.frame("y" = data4$Cooling_Load, "yhat" = predict(modelo_final, data4))
g1 <- ggplot(dt,
aes(x = y, y = .pred)) +
geom_point() + geom_line(aes(y = y), colour = "red", size = 1) +
labs(title = "Modelo SVM", subtitle = "y_ajustado vs y_real")
g1
