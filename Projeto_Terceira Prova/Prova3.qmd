---
title: "Prova 3 - Machine Learning"
author: "Eraldo Rocha"
date: last-modified
date-format: "DD MMM, YYYY"

format: 
  html:
    theme: lux
    code-fold: true
    code-tools: true
    code-block-bg: true
    code-block-border-left: "#9400D3"
    highlight-style: github
    code-link: true
    toc: true 
    toc-title: Sumário
    toc-location: left
    toc-depth: 3
    number-depth: 4
    smooth-scroll: true
    
self-contained: true
page-layout: full
editor: source
---

```{r, warning=FALSE}
rm(list = ls())
library(tidymodels)
tidymodels_prefer()
```


# Questão 1

Abaixo podemos visualizar um resumo das informações presente em nosso banco de dados, que consiste em 12 caracteristicas clínicas de 918 indivíduos diferentes. Das 12 características clínicas, 7 são variáveis categóricas e 5 variáveis numéricas. Além disso, na coluna n_missing, constata-se a completude do nosso banco de dados.

```{r}
url = 'https://raw.githubusercontent.com/eraldof/machine_learning/main/Projeto_Terceira%20Prova/heart.csv'
data <- read.csv(url)


data$Sex <- factor(data$Sex, levels = c("M","F"), labels = c("Masculino", "Feminino"))
data$ChestPainType <- factor(data$ChestPainType, levels = c("TA", "ATA", "NAP", "ASY"), labels = c("Angina Típica", "Angina Atípica", "Dor Não Anginosa", "Assintomática"))
data$FastingBS <- factor(data$FastingBS, levels = c(0,1),labels = c("C.C", "JejumBS > 120 mg/dl"))
data$RestingECG <- factor(data$RestingECG, levels = c("Normal", "ST", "LVH"), labels = c("Normal", "anormalidade da onda", "hipertrofia ventricular"))
data$ExerciseAngina <- factor(data$ExerciseAngina, levels = c("N", "Y"), labels = c("Não", "Sim"))
data$ST_Slope <- factor(data$ST_Slope, levels = c("Up", "Flat", "Down"), labels = c("Ascendente", "Plano", "Descendente"))
data$HeartDisease <- factor(data$HeartDisease, levels = c(0,1),labels = c("Normal", "Doença cardiaca"))
data$Oldpeak <- as.numeric(data$Oldpeak)


skimr::skim(data)
```

## Repartindo o banco de dados e criando a receita
```{r}
set.seed(2023)
splitted <- initial_split(data, prop = 0.80, strata = `HeartDisease`)
treinamento <- training(splitted)
teste <- testing(splitted)
```


```{r}
receita <- recipe(HeartDisease ~ ., data = treinamento) %>%
  recipes::step_dummy(all_nominal(), -all_outcomes()) %>% 
  recipes::step_zv(all_numeric(), -all_outcomes()) %>% 
  recipes::step_corr(all_predictors(), threshold = 0.7, method = "spearman")
```

## Treinando

```{r}

```

```{r}
log_reg <-
  logistic_reg(penalty = tune(), mixture = tune()) %>% # logistic regression
  set_engine(engine = "glmnet") %>%
  set_mode("classification")

wf <- workflow_set(
  preproc = list(receita),
  models = list(modelo_log = log_reg)
) %>%
  mutate(wflow_id = gsub("(recipe_)", "", wflow_id))

set.seed(2023)
vfold <- vfold_cv(treinamento,
                     v = 5,
                     strata = HeartDisease) 

grid_control <- control_grid(
  save_pred = TRUE,
  save_workflow = TRUE,
  parallel_over = "resamples"
)

metrica <- metric_set(accuracy, roc_auc)


```

```{r}
tunagem <- 
  wf %>% 
  workflow_map(
    verbose = TRUE,
    seed = 2023,
    resamples = vfold,
    control = grid_control,
    metrics = metrica,
    grid = 50L
  )
```

## Verificando os melhores hiperparametros
```{r}
best = tunagem %>% 
  extract_workflow_set_result("modelo_log") %>% 
  select_best(metric = "roc_auc")

best %>%
  knitr::kable()

test <-  tunagem %>% 
   extract_workflow("modelo_log") %>% 
   finalize_workflow(best) %>% 
   last_fit(split = splitted,
            metrics = metric_set(accuracy, roc_auc))
```

## Finalizando o modelo e testando em uma matriz de confusão
```{r}
predictions <- test %>%
  collect_predictions()

matriz_confusão <- predictions %>% 
  conf_mat(HeartDisease, .pred_class)

round(prop.table(matriz_confusão$table),2) %>%
  knitr::kable()
```


## Verificando a curva roc
```{r}
curva_roc <- roc_curve(predictions, HeartDisease, .pred_Normal)
roc_auc(predictions, HeartDisease, .pred_Normal)
autoplot(curva_roc)
```

O modelo em questão tem um desempenho melhor do que um classificador aleatório.



