---
title: "Prova 1 - Machine Learning"
author: "Eraldo Rocha"
format: 
  html:
    theme: lux
    code-fold: show
    code-tools: true
    code-block-bg: true
    code-block-border-left: "#9400D3"
    highlight-style: github
    code-link: true
    toc: true 
    toc-title: Sumário
    toc-location: left
    toc-depth: 2
    number-sections: true
    number-depth: 3
    smooth-scroll: true
    link-external-newwindow: true
fig-dpi: 1000
self-contained: true
page-layout: full
editor: source
---

# Questões Teóricas -

## Questão:

Com suas palavras, explique o dilema de balanço entre víes e variância.

`Resposta`: De maneira resumida, é um conflito de escolhas. Se você deseja um modelo com um viés baixo infelizmente você terá um modelo de alta variância. Se você desejar um modelo com uma variância baixa infelizmente terá de lidar com um modelo enviesado.

## Questão:

Explique resumidamente o que é aprendizagem supervisionada e não-supervisionada. Cite um problema de aprendizagem supervisionada e um outro de aprendizagem não-supervisionada.

`Resposta`: Aprendizagem **supervisionada** é tudo aquilo que você tem a resposta, já sabemos o **"lugar"** onde gostariamos de chegar. Exemplo prático: Certo banco de dados possui inúmeras medidas de animais diferentes e eu sei quais deles são ursos e quais não são, pode-se ajustar um modelo supervisionado, utilizando métodos de classificação.

`Resposta`: Já na aprendizagem **não** **supervisionada** não dispomos de um "**objetivo**" claro. Exemplo prático: Temos em mão dados de clientes de uma empresa e gostariamos de formar grupos de clientes com caracteristicas/gostos em comum para fornecermos um atendimento personalizado, com técnicas de clustering podemos formar N grupos diferentes e com a ajuda de um especialista devemos avaliar se esses grupos fazem sentido.

## Questão:

Explique qual o motivo que faz com que o Erro Quadrático Médio - EQM para avaliar o desempenho de um modelo é ruim quando não adotamos nenhuma estratégia de divisão do conjunto de dados em treinamento e teste.

`Resposta` Porque assim não gozamos da independencia entre variáveis e por conta disso não vale a lei dos grandes números.

# Questões Práticas -

```{r, warning=FALSE, message=FALSE}
rm(list = ls())
setwd("C:/Users/erald/Desktop/Faculdade/Aprendizagem de Maquina")
set.seed(2023)
library(rsample)
library(dplyr)
library(ggplot2)

```

## Questão:

Considere o conjunto de dados de Expectativa de vida versus PIB per Capita. Considere a função g uma regressão polinomia. Utilizando o erro quadrático médio observado, sem fazer nenhuma estratégia de divisão dos dados, implemente um código em R para checar qual o melhor modelo. p = 1, ..., 50.

```{r, warning=FALSE}
rm(list = ls())
dados_expectativa_renda <- read.csv("dados_expectativa_renda.csv")
set.seed(2023)
p = 50
dados_exp <- dados_expectativa_renda[,-1]
colnames(dados_exp) <- c("y", "x")

for(i in 1:p){
  if(i > 1){
    temp <- cbind(temp, temp[,2]^i)
    colnames(temp) <- c("y", "x", paste0("x", 2:i))
    fit <- lm(y~. , data = temp)
    eqm[i] <- mean((temp$y - predict(fit, newdata = temp))^2)
    i = i + 1
  }
  else{
    fit <- lm(y~. , data = dados_exp)
    eqm <- mean((dados_exp$y - predict(fit, newdata = dados_exp))^2)
    temp <- dados_exp
  }
}
eqm1 <- data.frame("P" = 1:50, "EQM" = eqm)

g <- ggplot(eqm1, aes(P, EQM)) + 
  geom_line(linetype = 2, size = 0.4) + 
  geom_point(size = 2, aes(colour = -EQM)) +
  scale_fill_brewer(palette = 1) + 
  labs(x = "P", y = "EQM",
       title = "Avaliação do EQM",
       subtitle = "Sem repartir conjunto treino / teste")
g


```

## Questão:

Refaça o exercício anterior do polinômio, utilizando a estratégia de data splitting, em que divide-se o conjunto de dados em treinamento e teste. Utilize o conjunto de teste para calcular a estimativa do risco, usando o EQM.

```{r, warning=FALSE}
rm(list = ls())
dados_expectativa_renda <- read.csv("dados_expectativa_renda.csv")
set.seed(2023)
p = 50
dados_exp <- dados_expectativa_renda[,-1]
colnames(dados_exp) <- c("y", "x")
dados_exp <- initial_split(dados_exp, prop = 3/4)
trainer <- training(dados_exp)
tester <- testing(dados_exp)

eqm2 = data.frame(P = 1:50, y = NA)
for(i in 1:p){
  if(i > 1){
    trainer <- cbind(trainer, trainer[,2]^i)
    colnames(trainer) <- c("y", "x", paste0("x", 2:i))
    fit <- lm(y~., trainer)
    
    ## Avaliando no conjunto de teste
    tester <- cbind(tester, tester[,2]^i)
    colnames(tester) <- c("y", "x", paste0("x", 2:i))
    eqm2[i,2] <- mean((tester[,1] - predict(fit, tester))^2)
  }
  else{
    fit <- lm(y~., trainer)
    eqm2[i,2] <- mean((tester[,1] - predict(fit, tester))^2)
  }
}

colnames(eqm2) <- c("P", "EQM")
g <- ggplot(eqm2, aes(P, EQM)) + 
  geom_line(linetype = 2, size = 0.4) + 
  geom_point(size = 2, aes(colour = -EQM)) +
  labs(x = "P", y = "EQM",
       title = "Avaliação do EQM",
       subtitle = "Repartindo conjunto treino/teste, sem validação cruzada") +
  xlim(c(0,18)) + ylim(c(10,130))

g

```

## Questão:

Ainda considerando o exercício do polinômio, implemente uma estratégia de leave-one-out cross-validation e selecione o melhor modelo minimizando a função de risco.

```{r, warning=FALSE}
rm(list = ls())
dados_expectativa_renda <- read.csv("dados_expectativa_renda.csv")
set.seed(2023)
p = 50
dados_exp <- dados_expectativa_renda[,-1]
colnames(dados_exp) <- c("y", "x")
dados_exp <- initial_split(dados_exp, prop = 3/4)
trainer <- training(dados_exp)
tester <- testing(dados_exp)

leave <- loo_cv(trainer)

results1 <- data.frame(P = NA, EQM = NA)
for(b in 1:dim(leave)[1]){
  eqm <- NULL
  
  for(i in 1:p){
    if(i > 1){
      temp_trainer <- leave$splits[[b]] %>% analysis()
      temp_tester <- leave$splits[[b]] %>% assessment()
      for(j in 2:i){
        temp_trainer <- cbind(temp_trainer, temp_trainer$x^j)
        temp_tester <- cbind(temp_tester, temp_tester$x^j)
        colnames(temp_trainer) <- c("y", "x", paste0("x", 2:j))
        colnames(temp_tester) <- c("y", "x", paste0("x", 2:j))
      }
      
      fit <- lm(y~., temp_trainer)
      eqm[i] <- as.numeric((temp_tester[,1] - predict(fit, temp_tester))^2)
    }
    else{
      temp_trainer <- leave$splits[[b]] %>% analysis()
      temp_tester <- leave$splits[[b]] %>% assessment()
      fit <- lm(y~., temp_trainer)
      eqm[i] <- as.numeric((temp_tester[,1] - predict(fit, newdata = temp_tester))^2)
    }
  }
  
  results1[b,1] <- which(eqm == min(eqm))[1]
  results1[b,2] <- min(eqm) 
}
```


`Resposta:` Polinômio de Grau `r results1[which(results1$EQM == min(results1)),1]` apresentou o menor EQM, no valor de `r min(results1)`.

## Questão:

Por fim, considerando o exercício do polinômio, rafaça-o utilizando um procedimento de k-fold cross-validation. Considere k=5. Dica: considere utilizar a biblioteca rsample.

```{r, warning=FALSE}
rm(list = ls())
dados_expectativa_renda <- read.csv("dados_expectativa_renda.csv")
set.seed(2023)
p = 50
k = 5
dados_exp <- dados_expectativa_renda[,-1]
colnames(dados_exp) <- c("y", "x")
dados_exp <- initial_split(dados_exp, prop = 3/4)
trainer <- training(dados_exp)
tester <- testing(dados_exp)

vfold <- vfold_cv(trainer, v = 5)

results2 <- data.frame(P = NA, EQM = NA)
for(b in 1:dim(vfold)[1]){
  eqm <- NULL
  
  for(i in 1:p){
    if(i > 1){
      temp_trainer <- vfold$splits[[b]] %>% analysis()
      temp_tester <- vfold$splits[[b]] %>% assessment()
      for(j in 2:i){
        temp_trainer <- cbind(temp_trainer, temp_trainer$x^j)
        temp_tester <- cbind(temp_tester, temp_tester$x^j)
        colnames(temp_trainer) <- c("y", "x", paste0("x", 2:j))
        colnames(temp_tester) <- c("y", "x", paste0("x", 2:j))
      }
      
      fit <- lm(y~., temp_trainer)
      eqm[i] <- mean((temp_tester[,1] - predict(fit, newdata = temp_tester))^2)
    }
    else{
      temp_trainer <- vfold$splits[[b]] %>% analysis()
      temp_tester <- vfold$splits[[b]] %>% assessment()
      fit <- lm(y~., temp_trainer)
      eqm[i] <- mean((temp_tester[,1] - predict(fit, newdata = temp_tester))^2)
    }
  }
  results2[b,1] <- which(eqm == min(eqm))[1]
  results2[b,2] <- min(eqm) 
}
```


`Resposta:` Polinômio de Grau `r results2[which(results2$EQM == min(results2$EQM)),1]` apresentou o menor EQM, no valor de `r min(results2$EQM)` para o método k-fold, k=5.



## Questão:

Utilizando os dados de vinho vermelho, faça uma pequena análise exploratória dos dados. No link do Kaggle você consegue uma explicação sobre o que significa cada uma das variáveis. 

```{r, warning=FALSE}
library(tidymodels)
library(tibble)
library(purrr)
library(ggplot2)
library(patchwork)

tidymodels::tidymodels_prefer()

```


```{r, warning=FALSE}
rm(list = ls())
wine <- read.csv("winequality-red.csv")
skimr::skim(wine)
```

Nosso banco de dados conta com 1599 observações e 12 variáveis numéricas, sendo 3 variáveis discretas e 9 contínuas. Abaixo uma breve descrição de cada uma das variáveis:

1.  Acidez Fixa;

2.  Acidez Volátil;

3.  Ácido cítrico -- É um ácido constituido das uvas que proporciona a sensação de frescor, podendo ser adicionado para aumentar a acidez;

4.  Açúcar residual -- Açucar que resta no vinho após sua fermentação alcoolíca;

5.  Cloretos -- São sais minerais;

6.  Dióxido de enxofre livre -- Químico responsável por evitar a oxidação do vinho;

7.  Dióxido de enxofre total -- Soma do dióxido de enxofre livre mais o combinado existente no vinho;

8.  Densidade -- É a massa volumêtrica do vinho sob a massa volumétrica da água;

9.  Ph -- Concentraçao de Ions de hidrogênio (H+) livres em uma solução de vinho;

10. Sulfatos;

11. Álcool -- Quantidade de Alcool;

12. Qualidade -- Uma pontuação entre 0 e 10;

## Questão:

obtenha o melhor modelo de regressão linear para modelar a qualidade do vinho, considerando: Método dos Mínimos Quadrados, Regressão Ridge, Regressão Lasso, Elastic Net.
Selecione o melhor modelo para cada uma das classes e contrua uma tabela com o risco estimado. Ao fim construir quatro gráficos mostrando cada um dos ajustes.

```{r, warning=FALSE}
colnames(wine) <- c(paste0("x", 1:11), "y")
#Data split
wine <- initial_split(wine, prop = 3/4)

trainer <- training(wine)
tester <- testing(wine)

#Setting Engine
modelo_eqm <- 
  linear_reg(penalty = 0, mixture = 0) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

modelo_ridge <- 
  linear_reg(penalty = tune::tune(), mixture = 0) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

modelo_lasso <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) %>% 
  set_mode("regression") %>% 
  parsnip::set_engine("glmnet")

modelo_elastic <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) %>% 
  set_mode("regression") %>% 
  parsnip::set_engine("glmnet")


#workflow
all_wf <- 
  workflow_set(
    preproc = list(y ~ . ),
    models = list(eqm = modelo_eqm, ridge = modelo_ridge, lasso = modelo_lasso, elastic = modelo_elastic), 
    cross = TRUE
  )

#cross-validation
set.seed(2023)
cv <- rsample::vfold_cv(trainer, v = 5L)

#metrics
metrica <- yardstick::metric_set(rmse)

#tunning
tunagem <- 
  all_wf %>%  
  workflow_map(
    seed = 2023, 
    verbose = TRUE,
    resamples = cv,
    grid = 50,
    metrics = metrica
  )

#melhores modelos
modelos_rank <- tunagem %>% rank_results()

melhor_eqm <- 
  tunagem %>% 
  extract_workflow_set_result("formula_eqm") %>% 
  select_best("rmse")

melhor_ridge <- 
  tunagem %>% 
  extract_workflow_set_result("formula_ridge") %>% 
  select_best("rmse")

melhor_lasso <- 
  tunagem %>% 
  extract_workflow_set_result("formula_lasso") %>% 
  select_best("rmse")

melhor_elastic <- 
  tunagem %>% 
  extract_workflow_set_result("formula_elastic") %>% 
  select_best("rmse")

finalizando_eqm <- 
  tunagem %>% 
  extract_workflow("formula_eqm") %>% 
  finalize_workflow(melhor_eqm) %>% 
  last_fit(split = wine)

finalizando_ridge <- 
  tunagem %>% 
  extract_workflow("formula_ridge") %>% 
  finalize_workflow(melhor_ridge) %>% 
  last_fit(split = wine)

finalizando_lasso <- 
  tunagem %>% 
  extract_workflow("formula_lasso") %>% 
  finalize_workflow(melhor_lasso) %>% 
  last_fit(split = wine)

finalizando_elastic <- 
  tunagem %>% 
  extract_workflow("formula_elastic") %>% 
  finalize_workflow(melhor_elastic) %>% 
  last_fit(split = wine)

# # Visualizando as métricas
# finalizando_eqm %>% collect_metrics()
# finalizando_ridge %>% collect_metrics()
# finalizando_lasso %>% collect_metrics()
# finalizando_elastic %>% collect_metrics()
# 
# # Visualizando predições:
# finalizando_eqm %>% collect_predictions()
# finalizando_ridge %>% collect_predictions()
# finalizando_lasso %>% collect_predictions()
# finalizando_elastic %>% collect_predictions()

```

```{r, warning=FALSE}
knitr::kable(data.frame(row.names = c("EQM", "Ridge", "Lasso", "Elastic"), 
                        "RMSE" = as.numeric(c((finalizando_eqm |> collect_metrics())[1,3],
                                              (finalizando_ridge |> collect_metrics())[1,3],
                                              (finalizando_lasso |> collect_metrics())[1,3],
                                              (finalizando_elastic |> collect_metrics())[1,3])))
             
             
)
```

